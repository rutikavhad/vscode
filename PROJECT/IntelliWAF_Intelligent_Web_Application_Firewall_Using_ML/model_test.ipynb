{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e9feaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db22bee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:95: SyntaxWarning: invalid escape sequence '\\,'\n",
      "<>:95: SyntaxWarning: invalid escape sequence '\\,'\n",
      "/tmp/ipykernel_10135/1184510237.py:95: SyntaxWarning: invalid escape sequence '\\,'\n",
      "  print(\"2025-12-24T09:17:16.000000Z,\\\"('127.0.0.1'\\, 31580)\\\",GET,http://192.168.122.170/dvwa/vulnerabilities/xss_r/?msg=Nice website,/dvwa/vulnerabilities/xss_r/,msg=Nice website,NORMAL,16.0,1.332,2.0,False,[1 0 0 0 0 0 0]\")\n",
      "/home/matrix/Documents/vscode/PROJECT/venv/lib/python3.13/site-packages/sklearn/base.py:442: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.6.1 when using version 1.7.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/tmp/ipykernel_10135/1184510237.py:95: SyntaxWarning: invalid escape sequence '\\,'\n",
      "  print(\"2025-12-24T09:17:16.000000Z,\\\"('127.0.0.1'\\, 31580)\\\",GET,http://192.168.122.170/dvwa/vulnerabilities/xss_r/?msg=Nice website,/dvwa/vulnerabilities/xss_r/,msg=Nice website,NORMAL,16.0,1.332,2.0,False,[1 0 0 0 0 0 0]\")\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "STACK_GLOBAL requires str",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnpicklingError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Load trained artifacts\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mfinal_rf_model.pkl\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     model = \u001b[43mpickle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mtfidf_vectorizer.pkl\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     12\u001b[39m     vectorizer = pickle.load(f)\n",
      "\u001b[31mUnpicklingError\u001b[39m: STACK_GLOBAL requires str"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "# ----------------------------\n",
    "# Load trained artifacts\n",
    "# ----------------------------\n",
    "with open(\"final_rf_model.pkl\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "with open(\"tfidf_vectorizer.pkl\", \"rb\") as f:\n",
    "    vectorizer = pickle.load(f)\n",
    "\n",
    "with open(\"attack_type_encoder.pkl\", \"rb\") as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "\n",
    "# ----------------------------\n",
    "# Parse single CSV-like line\n",
    "# ----------------------------\n",
    "def parse_input(line: str):\n",
    "    parts = []\n",
    "    current = \"\"\n",
    "    in_quotes = False\n",
    "\n",
    "    for char in line:\n",
    "        if char == '\"' and not in_quotes:\n",
    "            in_quotes = True\n",
    "            continue\n",
    "        elif char == '\"' and in_quotes:\n",
    "            in_quotes = False\n",
    "            continue\n",
    "\n",
    "        if char == \",\" and not in_quotes:\n",
    "            parts.append(current)\n",
    "            current = \"\"\n",
    "        else:\n",
    "            current += char\n",
    "\n",
    "    parts.append(current)\n",
    "\n",
    "    return parts\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Build feature vector\n",
    "# ----------------------------\n",
    "def build_features(parsed):\n",
    "    \"\"\"\n",
    "    Adjust indexes ONLY if your training order was different\n",
    "    \"\"\"\n",
    "    method = parsed[2]\n",
    "    url = parsed[3]\n",
    "    path = parsed[4]\n",
    "    body = parsed[5]\n",
    "\n",
    "    body_len = float(parsed[7])\n",
    "    entropy = float(parsed[8])\n",
    "    special_chars = float(parsed[9])\n",
    "    is_ddos = int(parsed[10] == \"True\")\n",
    "\n",
    "    # Combine text features (same logic as training)\n",
    "    text_payload = f\"{method} {url} {path} {body}\"\n",
    "\n",
    "    tfidf_features = vectorizer.transform([text_payload])\n",
    "\n",
    "    numeric_features = np.array(\n",
    "        [[body_len, entropy, special_chars, is_ddos]]\n",
    "    )\n",
    "\n",
    "    return tfidf_features, numeric_features\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Predict function\n",
    "# ----------------------------\n",
    "def predict_attack(line):\n",
    "    parsed = parse_input(line)\n",
    "    tfidf_features, numeric_features = build_features(parsed)\n",
    "\n",
    "    # Combine features\n",
    "    X = np.hstack([tfidf_features.toarray(), numeric_features])\n",
    "\n",
    "    pred_class = model.predict(X)[0]\n",
    "    proba = model.predict_proba(X).max()\n",
    "\n",
    "    attack_name = label_encoder.inverse_transform([pred_class])[0]\n",
    "\n",
    "    return attack_name, round(proba * 100, 2)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Run\n",
    "# ----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"2025-12-24T09:17:16.000000Z,\\\"('127.0.0.1'\\, 31580)\\\",GET,http://192.168.122.170/dvwa/vulnerabilities/xss_r/?msg=Nice website,/dvwa/vulnerabilities/xss_r/,msg=Nice website,NORMAL,16.0,1.332,2.0,False,[1 0 0 0 0 0 0]\")\n",
    "    user_input = input().strip()\n",
    "\n",
    "    attack, confidence = predict_attack(user_input)\n",
    "\n",
    "    print(\"\\n=== Prediction Result ===\")\n",
    "    print(f\"Attack Type : {attack}\")\n",
    "    print(f\"Confidence  : {confidence}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b61c0cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 2.3.2\n",
      "Uninstalling numpy-2.3.2:\n",
      "  Successfully uninstalled numpy-2.3.2\n",
      "Found existing installation: scikit-learn 1.7.1\n",
      "Uninstalling scikit-learn-1.7.1:\n",
      "  Successfully uninstalled scikit-learn-1.7.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting numpy==1.23.5\n",
      "  Downloading numpy-1.23.5.tar.gz (10.7 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m453.7 kB/s\u001b[0m  \u001b[33m0:00:23\u001b[0m \u001b[36m0:00:01\u001b[0m[36m0:00:02\u001b[0m:11\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[31mERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/matrix/Documents/vscode/PROJECT/venv/lib/python3.13/site-packages/pip/_internal/cli/base_command.py\", line 107, in _run_wrapper\n",
      "    status = _inner_run()\n",
      "  File \"/home/matrix/Documents/vscode/PROJECT/venv/lib/python3.13/site-packages/pip/_internal/cli/base_command.py\", line 98, in _inner_run\n",
      "    return self.run(options, args)\n",
      "           ~~~~~~~~^^^^^^^^^^^^^^^\n",
      "  File \"/home/matrix/Documents/vscode/PROJECT/venv/lib/python3.13/site-packages/pip/_internal/cli/req_command.py\", line 71, in wrapper\n",
      "    return func(self, options, args)\n",
      "  File \"/home/matrix/Documents/vscode/PROJECT/venv/lib/python3.13/site-packages/pip/_internal/commands/install.py\", line 393, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "        reqs, check_supported_wheels=not options.target_dir\n",
      "    )\n",
      "  File \"/home/matrix/Documents/vscode/PROJECT/venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 98, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "                            ~~~~~~~~~~~~~~~~^\n",
      "        collected.requirements, max_rounds=limit_how_complex_resolution_can_be\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/matrix/Documents/vscode/PROJECT/venv/lib/python3.13/site-packages/pip/_vendor/resolvelib/resolvers/resolution.py\", line 596, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "  File \"/home/matrix/Documents/vscode/PROJECT/venv/lib/python3.13/site-packages/pip/_vendor/resolvelib/resolvers/resolution.py\", line 429, in resolve\n",
      "    self._add_to_criteria(self.state.criteria, r, parent=None)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/matrix/Documents/vscode/PROJECT/venv/lib/python3.13/site-packages/pip/_vendor/resolvelib/resolvers/resolution.py\", line 150, in _add_to_criteria\n",
      "    if not criterion.candidates:\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/matrix/Documents/vscode/PROJECT/venv/lib/python3.13/site-packages/pip/_vendor/resolvelib/structs.py\", line 194, in __bool__\n",
      "    return bool(self._sequence)\n",
      "  File \"/home/matrix/Documents/vscode/PROJECT/venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 165, in __bool__\n",
      "    self._bool = any(self)\n",
      "                 ~~~^^^^^^\n",
      "  File \"/home/matrix/Documents/vscode/PROJECT/venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 149, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "                       ^^^^^^^^\n",
      "  File \"/home/matrix/Documents/vscode/PROJECT/venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 39, in _iter_built\n",
      "    candidate = func()\n",
      "  File \"/home/matrix/Documents/vscode/PROJECT/venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/factory.py\", line 180, in _make_candidate_from_link\n",
      "    base: BaseCandidate | None = self._make_base_candidate_from_link(\n",
      "                                 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        link, template, name, version\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/matrix/Documents/vscode/PROJECT/venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/factory.py\", line 226, in _make_base_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "                                       ~~~~~~~~~~~~~^\n",
      "        link,\n",
      "        ^^^^^\n",
      "    ...<3 lines>...\n",
      "        version=version,\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/matrix/Documents/vscode/PROJECT/venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 309, in __init__\n",
      "    super().__init__(\n",
      "    ~~~~~~~~~~~~~~~~^\n",
      "        link=link,\n",
      "        ^^^^^^^^^^\n",
      "    ...<4 lines>...\n",
      "        version=version,\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/matrix/Documents/vscode/PROJECT/venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 162, in __init__\n",
      "    self.dist = self._prepare()\n",
      "                ~~~~~~~~~~~~~^^\n",
      "  File \"/home/matrix/Documents/vscode/PROJECT/venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 239, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "  File \"/home/matrix/Documents/vscode/PROJECT/venv/lib/python3.13/site-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 320, in _prepare_distribution\n",
      "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/matrix/Documents/vscode/PROJECT/venv/lib/python3.13/site-packages/pip/_internal/operations/prepare.py\", line 537, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/matrix/Documents/vscode/PROJECT/venv/lib/python3.13/site-packages/pip/_internal/operations/prepare.py\", line 652, in _prepare_linked_requirement\n",
      "    dist = _get_prepared_distribution(\n",
      "        req,\n",
      "    ...<3 lines>...\n",
      "        self.check_build_deps,\n",
      "    )\n",
      "  File \"/home/matrix/Documents/vscode/PROJECT/venv/lib/python3.13/site-packages/pip/_internal/operations/prepare.py\", line 77, in _get_prepared_distribution\n",
      "    abstract_dist.prepare_distribution_metadata(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        build_env_installer, build_isolation, check_build_deps\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/matrix/Documents/vscode/PROJECT/venv/lib/python3.13/site-packages/pip/_internal/distributions/sdist.py\", line 59, in prepare_distribution_metadata\n",
      "    self._install_build_reqs(build_env_installer)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/matrix/Documents/vscode/PROJECT/venv/lib/python3.13/site-packages/pip/_internal/distributions/sdist.py\", line 133, in _install_build_reqs\n",
      "    build_reqs = self._get_build_requires_wheel()\n",
      "  File \"/home/matrix/Documents/vscode/PROJECT/venv/lib/python3.13/site-packages/pip/_internal/distributions/sdist.py\", line 108, in _get_build_requires_wheel\n",
      "    return backend.get_requires_for_build_wheel()\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"/home/matrix/Documents/vscode/PROJECT/venv/lib/python3.13/site-packages/pip/_internal/utils/misc.py\", line 694, in get_requires_for_build_wheel\n",
      "    return super().get_requires_for_build_wheel(config_settings=cs)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/matrix/Documents/vscode/PROJECT/venv/lib/python3.13/site-packages/pip/_vendor/pyproject_hooks/_impl.py\", line 196, in get_requires_for_build_wheel\n",
      "    return self._call_hook(\n",
      "           ~~~~~~~~~~~~~~~^\n",
      "        \"get_requires_for_build_wheel\", {\"config_settings\": config_settings}\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"/home/matrix/Documents/vscode/PROJECT/venv/lib/python3.13/site-packages/pip/_vendor/pyproject_hooks/_impl.py\", line 402, in _call_hook\n",
      "    raise BackendUnavailable(\n",
      "    ...<4 lines>...\n",
      "    )\n",
      "pip._vendor.pyproject_hooks._impl.BackendUnavailable: Cannot import 'setuptools.build_meta'\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25hNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall -y numpy scikit-learn\n",
    "%pip install numpy==1.23.5 scikit-learn==1.2.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60d5e8f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'final_rf_model.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# -----------------------------------\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Load trained artifacts (SAFE)\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# -----------------------------------\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m model = \u001b[43mjoblib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfinal_rf_model.joblib\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m vectorizer = joblib.load(\u001b[33m\"\u001b[39m\u001b[33mtfidf_vectorizer.joblib\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m label_encoder = joblib.load(\u001b[33m\"\u001b[39m\u001b[33mattack_type_encoder.joblib\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/vscode/PROJECT/venv/lib/python3.13/site-packages/joblib/numpy_pickle.py:735\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(filename, mmap_mode, ensure_native_byte_order)\u001b[39m\n\u001b[32m    733\u001b[39m         obj = _unpickle(fobj, ensure_native_byte_order=ensure_native_byte_order)\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m735\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    736\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m _validate_fileobject_and_memmap(f, filename, mmap_mode) \u001b[38;5;28;01mas\u001b[39;00m (\n\u001b[32m    737\u001b[39m             fobj,\n\u001b[32m    738\u001b[39m             validated_mmap_mode,\n\u001b[32m    739\u001b[39m         ):\n\u001b[32m    740\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    741\u001b[39m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[32m    742\u001b[39m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[32m    743\u001b[39m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'final_rf_model.joblib'"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# -----------------------------------\n",
    "# Load trained artifacts (SAFE)\n",
    "# -----------------------------------\n",
    "model = joblib.load(\"final_rf_model.joblib\")\n",
    "vectorizer = joblib.load(\"tfidf_vectorizer.joblib\")\n",
    "label_encoder = joblib.load(\"attack_type_encoder.joblib\")\n",
    "\n",
    "# -----------------------------------\n",
    "# Robust CSV-line parser\n",
    "# -----------------------------------\n",
    "def parse_csv_line(line):\n",
    "    pattern = re.compile(r'''\n",
    "        (?:^|,)\n",
    "        (?:\n",
    "          \"(.*?)\"     # quoted\n",
    "          |\n",
    "          ([^\",]+)    # unquoted\n",
    "        )\n",
    "    ''', re.VERBOSE)\n",
    "\n",
    "    fields = []\n",
    "    for match in pattern.finditer(line):\n",
    "        fields.append(match.group(1) or match.group(2))\n",
    "    return fields\n",
    "\n",
    "\n",
    "# -----------------------------------\n",
    "# Feature Engineering\n",
    "# -----------------------------------\n",
    "def build_features(fields):\n",
    "    \"\"\"\n",
    "    Column order must match training:\n",
    "    0 timestamp\n",
    "    1 client_ip\n",
    "    2 method\n",
    "    3 url\n",
    "    4 path\n",
    "    5 body\n",
    "    6 attack_type (ignored during prediction)\n",
    "    7 body_len\n",
    "    8 entropy\n",
    "    9 special_char_count\n",
    "    10 is_ddos\n",
    "    \"\"\"\n",
    "\n",
    "    method = fields[2]\n",
    "    url = fields[3]\n",
    "    path = fields[4]\n",
    "    body = fields[5]\n",
    "\n",
    "    body_len = float(fields[7])\n",
    "    entropy = float(fields[8])\n",
    "    special_chars = float(fields[9])\n",
    "    is_ddos = 1 if fields[10].lower() == \"true\" else 0\n",
    "\n",
    "    # Text payload (same logic as training)\n",
    "    text_payload = f\"{method} {url} {path} {body}\"\n",
    "\n",
    "    X_text = vectorizer.transform([text_payload]).toarray()\n",
    "\n",
    "    X_numeric = np.array([[body_len, entropy, special_chars, is_ddos]])\n",
    "\n",
    "    return np.hstack((X_text, X_numeric))\n",
    "\n",
    "\n",
    "# -----------------------------------\n",
    "# Prediction\n",
    "# -----------------------------------\n",
    "def predict_attack(line):\n",
    "    fields = parse_csv_line(line)\n",
    "\n",
    "    if len(fields) < 11:\n",
    "        raise ValueError(\"Invalid input format\")\n",
    "\n",
    "    X = build_features(fields)\n",
    "\n",
    "    pred = model.predict(X)[0]\n",
    "    prob = model.predict_proba(X).max()\n",
    "\n",
    "    attack_name = label_encoder.inverse_transform([pred])[0]\n",
    "\n",
    "    return attack_name, round(prob * 100, 2)\n",
    "\n",
    "\n",
    "# -----------------------------------\n",
    "# CLI\n",
    "# -----------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\nPaste full request line:\")\n",
    "    line = input().strip()\n",
    "\n",
    "    attack, confidence = predict_attack(line)\n",
    "\n",
    "    print(\"\\n========== RESULT ==========\")\n",
    "    print(f\"Attack Type : {attack}\")\n",
    "    print(f\"Confidence  : {confidence}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21aef81e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
